---
permalink: /
title: "Welcome to David Kim's Homepage"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## My Academic Goal and Research

 Understanding how an individual’s behavior reflects his/her comprehension,intention, and cognitive state is an interesting topic that can be used in many ways, such as predicting future achievements, diagnosing one’s learning processes, and more. My research goal is to create a solid framework that uses Machine Learning (ML) and Deep Learning (DL) to infer explanatory variables ofhuman behavior from real-world data, then further apply them to support or refute hypotheses regarding the human mind. There are various and thorough studies on this topic that have yet to be conducted. Two critical problems come to mind. First, it is vague and uncertain about how to measure and quantify the mechanisms of human behavior. Second, previous models are not powerful enough to fully capture the various factors that determine human behavior. However, with the development of ML/DL, we may have achance to overcome these limitations. Natural language processing research has opened the possibility of quantifying natural language semantics. With recurrent neural networks we are able to analyze sequences of human actions such as their reading patterns. Computer vision models can support neuroscience research that utilizes functional MRI (fMRI) to visualize the human brain. Despite this fascinating research, most of the results are based on fairly structured data. Most of the time, the input variables and optimization processare relatively straightforward, but human behavior data usually do not have this luxury. Hence there exists a gap in applying ML/DL models to analyze human behavior effectively. I intend to reduce this gap and model human behavior, which will enhance our practical ability to understand and predict the human mind.

 I am currently working with my advisor [Michael C. Mozer](https://www.cs.colorado.edu/~mozer/index.php) as a Research Assitance for about an year. During this period we have published one [Workshop paper](https://www.cs.colorado.edu/~mozer/Research/Selected%20Publications/reprints/Kimetal2020.pdf) and continuing to produce more results. The overall research project focus on developing intelligent textbooks which infer student understanding based on students' interactions with the textbooks. Given a model of the student's knowledge state, we then hope to customize material for further study and review.

Data were collected in collaboration with [OpenStax](https://openstax.org/), a nonprofit organization that supports open-access college-level digital textbooks. For two full semesters data were collected in Biology, Physics, Sociology, and History classes with 11,134 students. In these classes, students were able to highlight and add annotations to their e-textbooks while reading. Of the 11,134 students, 2,829 used the highlighting facility. Given the record of these highlights and annotation, we attempt to infer student comprehension, as assessed by a quiz that students take at the end of each section as well as delayed review questions administered about a week after initial reading.

The goal is to predict quiz performance from the pattern of highlighting. In the previous workshop paper, we built separate linear models for each section of text.  (A section of text is the unit we analyze and the unit that students are quizzed on.) The input data used for prediction is a high dimensional binary feature vector where each feature indicates whether or not a given word of a section is highlighted. The first hurdle was to find the best representation of highlights as input to the linear model. In my [previous work](https://www.cs.colorado.edu/~mozer/Research/Selected%20Publications/reprints/Kimetal2020.pdf), we found that parsing the whole passage into words and reducing the dimension using PCA (Principal Component Analysis) can explain about 13% variance of the test performance. Although, this is an exciting result, this method has two problems. First, is that it is yet to be proven to be generalized in different sections and second it is extremely limited in that it is text dependent: we build a separate model for each section of text and therefore require training data for each section.


